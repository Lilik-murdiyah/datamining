Traceback (most recent call last):
  File "/usr/local/lib/python3.7/dist-packages/jupyter_cache/executors/utils.py", line 56, in single_nb_execution
    record_timing=False,
  File "/usr/local/lib/python3.7/dist-packages/nbclient/client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "/usr/local/lib/python3.7/dist-packages/nbclient/util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "/usr/local/lib/python3.7/dist-packages/nbclient/util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "/usr/lib/python3.7/asyncio/base_events.py", line 587, in run_until_complete
    return future.result()
  File "/usr/local/lib/python3.7/dist-packages/nbclient/client.py", line 664, in async_execute
    cell, index, execution_count=self.code_cells_executed + 1
  File "/usr/local/lib/python3.7/dist-packages/nbclient/client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "/usr/local/lib/python3.7/dist-packages/nbclient/client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
from numpy.core.defchararray import count
import pandas as pd
import numpy as np
import numpy as np
from math import log2

def main():
    s = pd.read_csv(url)
    print("******************************************************")
    print("Entropy Discretization                         STARTED")
    s = entropy_discretization(s)
    print("Entropy Discretization                         COMPLETED")

# This method discretizes attribute A1
# If the information gain is 0, i.e the number of 
# distinct class is 1 or
# If min f/ max f < 0.5 and the number of distinct values is floor(n/2)
# Then that partition stops splitting.
# This method discretizes s A1
# If the information gain is 0, i.e the number of 
# distinct class is 1 or
# If min f/ max f < 0.5 and the number of distinct values is floor(n/2)
# Then that partition stops splitting.
def entropy_discretization(s):

    I = {}
    i = 0
    while(uniqueValue(s)):
        # Step 1: pick a threshold
        threshold = df['A1'].iloc[0]

        # Step 2: Partititon the data set into two parttitions
        df1 = s[s['bp_before'] < threshold]
        print("s1 after spitting")
        print(s1)
        print("******************")
        s2 = s[s['bp_before'] >= threshold]
        print("s2 after spitting")
        print(s2)
        print("******************")
            
        # Step 3: calculate the information gain.
        informationGain = information_gain(s1,s2,s)
        I.update({f'informationGain_{i}':informationGain,f'threshold_{i}': threshold})
        print(f'added informationGain_{i}: {informationGain}, threshold_{i}: {threshold}')
        s = s[s['A1'] != threshold]
        i += 1

    # Step 5: calculate the min information gain
    n = int(((len(I)/2)-1))
    print("Calculating minimum threshold")
    print("*****************************")
    minInformationGain = 0
    minThreshold       = 0 
    for i in range(0, n):
        if(I[f'informationGain_{i}'] < minInformationGain):
            minInformationGain = I[f'informationGain_{i}']
            minThreshold       = I[f'threshold_{i}']

    print(f'minThreshold: {minThreshold}, minInformationGain: {minInformationGain}')

    # Step 6: keep the partitions of S based on the value of threshold_i
    minPartition(minInformationGain,minThreshold,s,s1,s2)

def uniqueValue(s):
    # are records in s the same? return true
    if s.nunique()['bp_before'] == 1:
        return False
    # otherwise false 
    else:
        return True

def minPartition(minInformationGain,minThreshold,s,s1,s2):
    print(f'informationGain: {minInformationGain}, threshold: {minThreshold}')
    merged_partitions =  pd.merge(s1,s2)
    merged_partitions =  pd.merge(merged_partitions,s)
    print("Best Partition")
    print("***************")
    print(merged_partitions)
    print("***************")
    return merged_partitions




def information_gain(s1, s2, s):
    # calculate cardinality for s1
    cardinalityS1 = len(pd.Index(s1['A1']).value_counts())
    print(f'The Cardinality of s1 is: {cardinalityS1}')
    # calculate cardinality for s2
    cardinalityS2 = len(pd.Index(s2['A1']).value_counts())
    print(f'The Cardinality of s2 is: {cardinalityS2}')
    # calculate cardinality of s
    cardinalityS = len(pd.Index(s['A1']).value_counts())
    print(f'The Cardinality of s is: {cardinalityS}')
    # calculate informationGain
    informationGain = (cardinalityS1/cardinalityS) * entropy(s1) + (cardinalityS2/cardinalityS) * entropy(s2)
    print(f'The total informationGain is: {informationGain}')
    return informationGain



def entropy(s):
    print("calculating the entropy for s")
    print("*****************************")
    print(s)
    print("*****************************")

    # initialize ent
    ent = 0

    # calculate the number of classes in s
    numberOfClasses = s['Class'].nunique()
    print(f'Number of classes for dataset: {numberOfClasses}')
    value_counts = s['Class'].value_counts()
    p = []
    for i in range(0,numberOfClasses):
        n = s['Class'].count()
        # calculate the frequency of class_i in S1
        print(f'p{i} {value_counts.iloc[i]}/{n}')
        f = value_counts.iloc[i]
        pi = f/n
        p.append(pi)
    
    print(p)

    for pi in p:
        ent += -pi*log2(pi)

    return ent

main()
------------------

[0;31m[0m
[0;31mKeyError[0mTraceback (most recent call last)
[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py[0m in [0;36mget_loc[0;34m(self, key, method, tolerance)[0m
[1;32m   3360[0m             [0;32mtry[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 3361[0;31m                 [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_engine[0m[0;34m.[0m[0mget_loc[0m[0;34m([0m[0mcasted_key[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   3362[0m             [0;32mexcept[0m [0mKeyError[0m [0;32mas[0m [0merr[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx[0m in [0;36mpandas._libs.index.IndexEngine.get_loc[0;34m()[0m

[0;32m/usr/local/lib/python3.7/dist-packages/pandas/_libs/index.pyx[0m in [0;36mpandas._libs.index.IndexEngine.get_loc[0;34m()[0m

[0;32mpandas/_libs/hashtable_class_helper.pxi[0m in [0;36mpandas._libs.hashtable.PyObjectHashTable.get_item[0;34m()[0m

[0;32mpandas/_libs/hashtable_class_helper.pxi[0m in [0;36mpandas._libs.hashtable.PyObjectHashTable.get_item[0;34m()[0m

[0;31mKeyError[0m: 'A1'

The above exception was the direct cause of the following exception:

[0;31mKeyError[0mTraceback (most recent call last)
[0;32m<ipython-input-6-55b6878a49c1>[0m in [0;36m<module>[0;34m[0m
[1;32m    130[0m     [0;32mreturn[0m [0ment[0m[0;34m[0m[0;34m[0m[0m
[1;32m    131[0m [0;34m[0m[0m
[0;32m--> 132[0;31m [0mmain[0m[0;34m([0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m
[0;32m<ipython-input-6-55b6878a49c1>[0m in [0;36mmain[0;34m()[0m
[1;32m      9[0m     [0mprint[0m[0;34m([0m[0;34m"******************************************************"[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     10[0m     [0mprint[0m[0;34m([0m[0;34m"Entropy Discretization                         STARTED"[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 11[0;31m     [0ms[0m [0;34m=[0m [0mentropy_discretization[0m[0;34m([0m[0ms[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     12[0m     [0mprint[0m[0;34m([0m[0;34m"Entropy Discretization                         COMPLETED"[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m     13[0m [0;34m[0m[0m

[0;32m<ipython-input-6-55b6878a49c1>[0m in [0;36mentropy_discretization[0;34m(s)[0m
[1;32m     28[0m     [0;32mwhile[0m[0;34m([0m[0muniqueValue[0m[0;34m([0m[0ms[0m[0;34m)[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m     29[0m         [0;31m# Step 1: pick a threshold[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m
[0;32m---> 30[0;31m         [0mthreshold[0m [0;34m=[0m [0mdf[0m[0;34m[[0m[0;34m'A1'[0m[0;34m][0m[0;34m.[0m[0miloc[0m[0;34m[[0m[0;36m0[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m     31[0m [0;34m[0m[0m
[1;32m     32[0m         [0;31m# Step 2: Partititon the data set into two parttitions[0m[0;34m[0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/frame.py[0m in [0;36m__getitem__[0;34m(self, key)[0m
[1;32m   3456[0m             [0;32mif[0m [0mself[0m[0;34m.[0m[0mcolumns[0m[0;34m.[0m[0mnlevels[0m [0;34m>[0m [0;36m1[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   3457[0m                 [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_getitem_multilevel[0m[0;34m([0m[0mkey[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 3458[0;31m             [0mindexer[0m [0;34m=[0m [0mself[0m[0;34m.[0m[0mcolumns[0m[0;34m.[0m[0mget_loc[0m[0;34m([0m[0mkey[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   3459[0m             [0;32mif[0m [0mis_integer[0m[0;34m([0m[0mindexer[0m[0;34m)[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[1;32m   3460[0m                 [0mindexer[0m [0;34m=[0m [0;34m[[0m[0mindexer[0m[0;34m][0m[0;34m[0m[0;34m[0m[0m

[0;32m/usr/local/lib/python3.7/dist-packages/pandas/core/indexes/base.py[0m in [0;36mget_loc[0;34m(self, key, method, tolerance)[0m
[1;32m   3361[0m                 [0;32mreturn[0m [0mself[0m[0;34m.[0m[0m_engine[0m[0;34m.[0m[0mget_loc[0m[0;34m([0m[0mcasted_key[0m[0;34m)[0m[0;34m[0m[0;34m[0m[0m
[1;32m   3362[0m             [0;32mexcept[0m [0mKeyError[0m [0;32mas[0m [0merr[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m
[0;32m-> 3363[0;31m                 [0;32mraise[0m [0mKeyError[0m[0;34m([0m[0mkey[0m[0;34m)[0m [0;32mfrom[0m [0merr[0m[0;34m[0m[0;34m[0m[0m
[0m[1;32m   3364[0m [0;34m[0m[0m
[1;32m   3365[0m         [0;32mif[0m [0mis_scalar[0m[0;34m([0m[0mkey[0m[0;34m)[0m [0;32mand[0m [0misna[0m[0;34m([0m[0mkey[0m[0;34m)[0m [0;32mand[0m [0;32mnot[0m [0mself[0m[0;34m.[0m[0mhasnans[0m[0;34m:[0m[0;34m[0m[0;34m[0m[0m

[0;31mKeyError[0m: 'A1'
KeyError: 'A1'

